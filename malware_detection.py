import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import time

# Load the dataset
data = pd.read_csv('malware_dataset.csv')

# Encode the categorical features
le = LabelEncoder()
for col in data.select_dtypes(include='object'):
    data[col] = le.fit_transform(data[col])

# Split the dataset into training and testing sets
X = data.drop(['Result'], axis=1)
y = data['Result']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train the Decision Tree Classifier
dtc = DecisionTreeClassifier()
start_time = time.time()
dtc.fit(X_train, y_train)
y_pred = dtc.predict(X_test)
dtc_time = time.time() - start_time
dtc_accuracy = accuracy_score(y_test, y_pred)
dtc_precision = precision_score(y_test, y_pred)
dtc_recall = recall_score(y_test, y_pred)
dtc_f1 = f1_score(y_test, y_pred)

# Train the Random Forest Classifier
rfc = RandomForestClassifier()
start_time = time.time()
rfc.fit(X_train, y_train)
y_pred = rfc.predict(X_test)
rfc_time = time.time() - start_time
rfc_accuracy = accuracy_score(y_test, y_pred)
rfc_precision = precision_score(y_test, y_pred)
rfc_recall = recall_score(y_test, y_pred)
rfc_f1 = f1_score(y_test, y_pred)

# Train the Logistic Regression Algorithm
lr = LogisticRegression(max_iter=10000)
start_time = time.time()
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)
lr_time = time.time() - start_time
lr_accuracy = accuracy_score(y_test, y_pred)
lr_precision = precision_score(y_test, y_pred)
lr_recall = recall_score(y_test, y_pred)
lr_f1 = f1_score(y_test, y_pred)

# Train the Support Vector Machine Algorithm with a linear kernel on a subset of the data
svm = SVC(kernel='linear')
subset_indices = X_train.sample(n=42, random_state=42).index
start_time = time.time()
svm.fit(X_train.loc[subset_indices], y_train.loc[subset_indices])
y_pred = svm.predict(X_test)
svm_time = time.time() - start_time
svm_accuracy = accuracy_score(y_test, y_pred)
svm_precision = precision_score(y_test, y_pred)
svm_recall = recall_score(y_test, y_pred)
svm_f1 = f1_score(y_test, y_pred)

# Print the metric scores and times for all four algorithms
print('Decision Tree Algorithm:')
print('Accuracy:', '{:.2%}'.format(dtc_accuracy))
print('Precision:', '{:.2%}'.format(dtc_precision))
print('Recall:', '{:.2%}'.format(dtc_recall))
print('F1 score:', '{:.2%}'.format(dtc_f1))
print('Time taken:', '{:.3f} seconds'.format(dtc_time))

print('\nRandom Forest Algorithm:')
print('Accuracy:', '{:.2%}'.format(rfc_accuracy))
print('Precision:', '{:.2%}'.format(rfc_precision))
print('Recall:', '{:.2%}'.format(rfc_recall))
print('F1 score:', '{:.2%}'.format(rfc_f1))
print('Time taken:', '{:.3f} seconds'.format(rfc_time))

print('\nLogistic Regression Algorithm:')
print('Accuracy:', '{:.2%}'.format(lr_accuracy))
print('Precision:', '{:.2%}'.format(lr_precision))
print('Recall:', '{:.2%}'.format(lr_recall))
print('F1 score:', '{:.2%}'.format(lr_f1))
print('Time taken:', '{:.3f} seconds'.format(lr_time))

print('\nSupport Vector Machine Algorithm:')
print('Accuracy:', '{:.2%}'.format(svm_accuracy))
print('Precision:', '{:.2%}'.format(svm_precision))
print('Recall:', '{:.2%}'.format(svm_recall))
print('F1 score:', '{:.2%}'.format(svm_f1))
print('Time taken:', '{:.3f} seconds'.format(svm_time))

# Set up the data for the line graphs
algorithms = ['DT', 'RF', 'LR', 'SVM']
metrics = ['Accuracy', 'Precision', 'Recall', 'F1 score', 'Time taken']
accuracy_scores = [dtc_accuracy, rfc_accuracy, lr_accuracy, svm_accuracy]
precision_scores = [dtc_precision, rfc_precision, lr_precision, svm_precision]
recall_scores = [dtc_recall, rfc_recall, lr_recall, svm_recall]
f1_scores = [dtc_f1, rfc_f1, lr_f1, svm_f1]
times = [dtc_time, rfc_time, lr_time, svm_time]

# Create the line graphs
fig, axs = plt.subplots(2, 3, figsize=(15, 10))

# Plot accuracy scores
axs[0, 0].plot(algorithms, accuracy_scores, marker='o', linestyle='-')
axs[0, 0].set_title('Accuracy Scores')
axs[0, 0].set_ylabel('Accuracy')
axs[0, 0].set_ylim([0.75, 1.2])

# Plot precision scores
axs[0, 1].plot(algorithms, precision_scores, marker='o', linestyle='-')
axs[0, 1].set_title('Precision Scores')
axs[0, 1].set_ylabel('Precision')
axs[0, 1].set_ylim([0.65, 1.2])

# Plot recall scores
axs[0, 2].plot(algorithms, recall_scores, marker='o', linestyle='-')
axs[0, 2].set_title('Recall Scores')
axs[0, 2].set_ylabel('Recall')
axs[0, 2].set_ylim([0.85, 1.2])

# Plot F1 scores
axs[1, 0].plot(algorithms, f1_scores, marker='o', linestyle='-')
axs[1, 0].set_title('F1 Scores')
axs[1, 0].set_ylabel('F1 Score')
axs[1, 0].set_ylim([0.76, 1.2])

# Plot time taken for testing
axs[1, 1].plot(algorithms, times, marker='o', linestyle='-')
axs[1, 1].set_title('Time Taken for Testing')
axs[1, 1].set_ylabel('Time (s)')
axs[1, 1].set_ylim([0, 2.2])

# Remove the empty subplot
fig.delaxes(axs[1, 2])

plt.show()